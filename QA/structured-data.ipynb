{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab34d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5304b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.236 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.0 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "MAX_SCENES = 2\n",
    "DATA_VER = 'v1.0-mini'\n",
    "DATA_ROOT = '/users/bangya/projects/vlm/nuscenes-data'\n",
    "OUTPUT_ROOT = './structured-data'\n",
    "SENSOR = 'CAM_FRONT'\n",
    "POSTFIX = 'jpg'\n",
    "\n",
    "\"\"\"\n",
    "structured-data\n",
    " - scene_token\n",
    "    - sample_token\n",
    "      SENSOR_raw.jpg\n",
    "      SENSOR_box.jpg\n",
    "      SENSOR_meta.json\n",
    "\"\"\"\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "nusc = NuScenes(version=DATA_VER, dataroot=DATA_ROOT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5809ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corners_8_to_2(corners_8, W, H):\n",
    "    left_x = np.min(corners_8[0, :])\n",
    "    right_x = np.max(corners_8[0, :])\n",
    "    top_y = np.max(corners_8[1, :])\n",
    "    bottom_y = np.min(corners_8[1, :])\n",
    "    \n",
    "    # clipping\n",
    "    left_x = np.clip(left_x, 0, W)\n",
    "    right_x = np.clip(right_x, 0, W)\n",
    "    top_y = np.clip(top_y, 0, H)\n",
    "    bottom_y = np.clip(bottom_y, 0, H)\n",
    "\n",
    "    return np.array([[left_x, right_x], [bottom_y, top_y]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b900030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing scene cc8c0bf57f984915a77078b10eb33198 ...\n",
      " - Scene cc8c0bf57f984915a77078b10eb33198 has 39 frames.\n",
      " > Processing scene fcbccedd61424f1b85dcbf8f897f9754 ...\n",
      " - Scene fcbccedd61424f1b85dcbf8f897f9754 has 40 frames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sc in nusc.scene[:MAX_SCENES]:\n",
    "    print(f\" > Processing scene {sc['token']} ...\")\n",
    "    sc_dir = os.path.join(OUTPUT_ROOT, sc['token'])\n",
    "    os.makedirs(sc_dir, exist_ok=True)\n",
    "\n",
    "    first_frame = nusc.get('sample', sc['first_sample_token'])\n",
    "    all_frames = []\n",
    "    all_frames.append(first_frame)\n",
    "\n",
    "    while True:\n",
    "        if all_frames[-1]['next'] == '':\n",
    "            break\n",
    "        all_frames.append(nusc.get('sample', all_frames[-1]['next']))\n",
    "    print(f\" - Scene {sc['token']} has {len(all_frames)} frames.\")\n",
    "\n",
    "    for frame in all_frames:\n",
    "        frame_dir = os.path.join(sc_dir, str(frame['timestamp']))\n",
    "        os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "        # Copy RGB image\n",
    "        raw_path = nusc.get_sample_data_path(frame['data'][SENSOR])\n",
    "        rgb_path = os.path.join(frame_dir, f'{SENSOR}_raw.{POSTFIX}')\n",
    "        shutil.copy(raw_path, rgb_path)\n",
    "\n",
    "        # dump RGB image with boxes\n",
    "        rgb_box_path = os.path.join(frame_dir, f'{SENSOR}_box.{POSTFIX}')\n",
    "        box_per_annos = nusc.render_sample_data(frame['data'][SENSOR], out_path=rgb_box_path, verbose=False)\n",
    "\n",
    "        # dump meta data\n",
    "        anno_path = os.path.join(frame_dir, f'{SENSOR}_meta.json')\n",
    "        meta = {\n",
    "            'scene_token': sc['token'],\n",
    "            'sample_token': frame['token'],\n",
    "            'sample_data_token': frame['data'][SENSOR],\n",
    "            'timestamp': frame['timestamp'],\n",
    "            'image_path': rgb_path,\n",
    "            'image_box_path': rgb_box_path,\n",
    "            'image_width': nusc.get('sample_data', frame['data'][SENSOR])['width'],\n",
    "            'image_height': nusc.get('sample_data', frame['data'][SENSOR])['height'],\n",
    "            'cam_t': nusc.get('calibrated_sensor', nusc.get('sample_data', frame['data'][SENSOR])['calibrated_sensor_token'])['translation'],\n",
    "            'cam_r': nusc.get('calibrated_sensor', nusc.get('sample_data', frame['data'][SENSOR])['calibrated_sensor_token'])['rotation'],\n",
    "            'intrinsic': nusc.get('calibrated_sensor', nusc.get('sample_data', frame['data'][SENSOR])['calibrated_sensor_token'])['camera_intrinsic'],\n",
    "            'annos' : [],\n",
    "        }\n",
    "\n",
    "        annos = []\n",
    "        for anno_token, details in box_per_annos.items():\n",
    "            if details is None:\n",
    "                continue\n",
    "            anno = nusc.get('sample_annotation', anno_token)\n",
    "            visibility_token = anno['visibility_token']\n",
    "            visibility = nusc.get('visibility', visibility_token)['level']\n",
    "            diag = corners_8_to_2(details['corners'], meta['image_width'], meta['image_height']) \n",
    "\n",
    "            annos.append({\n",
    "                'anno_token': anno_token,\n",
    "                'category_name': anno['category_name'],\n",
    "                'box_t': anno['translation'],\n",
    "                'box_r': anno['rotation'],\n",
    "                'box_size': anno['size'],\n",
    "                'visibility': visibility,\n",
    "                '2d_crop': {\n",
    "                    'diag': diag.tolist(),\n",
    "                    'area': float((diag[0, 1] - diag[0, 0]) * (diag[1, 1] - diag[1, 0])),\n",
    "                },\n",
    "            })\n",
    "        meta['annos'] = annos\n",
    "\n",
    "        with open(anno_path, 'w') as f:\n",
    "            json.dump(meta, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
