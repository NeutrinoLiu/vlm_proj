{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab34d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SCENES = -1\n",
    "DATA_VER = 'v1.0-trainval'\n",
    "DATA_ROOT = '/users/bangya/projects/vlm/nuscenes-data'\n",
    "OUTPUT_ROOT = './structured-data'\n",
    "CROPS_ROOT = './instance_crops'\n",
    "SENSOR = 'CAM_FRONT'\n",
    "POSTFIX = 'jpg'\n",
    "\n",
    "\"\"\"\n",
    "structured-data\n",
    " - scene_token\n",
    "    - sample_token\n",
    "      SENSOR_raw.jpg\n",
    "      SENSOR_box.jpg\n",
    "      SENSOR_meta.json\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "instance_crops\n",
    " - scene_token\n",
    "    INSTANCE.jpg\n",
    "\"\"\"\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "nusc = NuScenes(version=DATA_VER, dataroot=DATA_ROOT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5809ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corners_8_to_2(corners_8, W, H):\n",
    "    left_x = np.min(corners_8[0, :])\n",
    "    right_x = np.max(corners_8[0, :])\n",
    "    top_y = np.max(corners_8[1, :])\n",
    "    bottom_y = np.min(corners_8[1, :])\n",
    "    \n",
    "    # clipping\n",
    "    left_x = np.clip(left_x, 0, W)\n",
    "    right_x = np.clip(right_x, 0, W)\n",
    "    top_y = np.clip(top_y, 0, H)\n",
    "    bottom_y = np.clip(bottom_y, 0, H)\n",
    "\n",
    "    return np.array([[left_x, right_x], [bottom_y, top_y]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b900030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sc in nusc.scene:\n",
    "    inst_crops = {} # token: [image_path, 2d_crop_diag, 2d_crop_area, visb]\n",
    "\n",
    "    print(f\" > Processing scene {sc['token']} ...\")\n",
    "    sc_dir = os.path.join(OUTPUT_ROOT, sc['token'])\n",
    "    # if os.path.exists(sc_dir):\n",
    "    #     print(f\" - Scene {sc['token']} already exists, skip.\")\n",
    "    #     continue\n",
    "    os.makedirs(sc_dir, exist_ok=True)\n",
    "\n",
    "    first_frame = nusc.get('sample', sc['first_sample_token'])\n",
    "    all_frames = []\n",
    "    all_frames.append(first_frame)\n",
    "\n",
    "    while True:\n",
    "        if all_frames[-1]['next'] == '':\n",
    "            break\n",
    "        all_frames.append(nusc.get('sample', all_frames[-1]['next']))\n",
    "    print(f\" - Scene {sc['token']} has {len(all_frames)} frames.\")\n",
    "\n",
    "    for frame in all_frames:\n",
    "        frame_dir = os.path.join(sc_dir, str(frame['timestamp']))\n",
    "        os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "        # Copy RGB image\n",
    "        raw_path = nusc.get_sample_data_path(frame['data'][SENSOR])\n",
    "        rgb_path = os.path.join(frame_dir, f'{SENSOR}_raw.{POSTFIX}')\n",
    "        shutil.copy(raw_path, rgb_path)\n",
    "\n",
    "        # dump RGB image with boxes\n",
    "        rgb_box_path = os.path.join(frame_dir, f'{SENSOR}_box.{POSTFIX}')\n",
    "        box_per_annos = nusc.render_sample_data(frame['data'][SENSOR], out_path=rgb_box_path, verbose=False)\n",
    "\n",
    "        # dump meta data\n",
    "        anno_path = os.path.join(frame_dir, f'{SENSOR}_meta.json')\n",
    "        meta = {\n",
    "            'scene_token': sc['token'],\n",
    "            'sample_token': frame['token'],\n",
    "            'sample_data_token': frame['data'][SENSOR],\n",
    "            'timestamp': frame['timestamp'],\n",
    "            'image_path': rgb_path,\n",
    "            'image_box_path': rgb_box_path,\n",
    "            'image_width': nusc.get('sample_data', frame['data'][SENSOR])['width'],\n",
    "            'image_height': nusc.get('sample_data', frame['data'][SENSOR])['height'],\n",
    "            'cam_t': nusc.get('ego_pose', nusc.get('sample_data', frame['data'][SENSOR])['ego_pose_token'])['translation'],\n",
    "            'cam_r': nusc.get('ego_pose', nusc.get('sample_data', frame['data'][SENSOR])['ego_pose_token'])['rotation'],\n",
    "            # 'cam_left_t': nusc.get('ego_pose', nusc.get('sample_data', frame['data'][SENSOR+\"_LEFT\"])['ego_pose_token'])['translation'],\n",
    "            # 'cam_left_r': nusc.get('ego_pose', nusc.get('sample_data', frame['data'][SENSOR+\"_LEFT\"])['ego_pose_token'])['rotation'],\n",
    "            'intrinsic': nusc.get('calibrated_sensor', nusc.get('sample_data', frame['data'][SENSOR])['calibrated_sensor_token'])['camera_intrinsic'],\n",
    "            'annos' : [],\n",
    "        }\n",
    "\n",
    "        annos = []\n",
    "        for anno_token, details in box_per_annos.items():\n",
    "            if details is None:\n",
    "                continue\n",
    "            anno = nusc.get('sample_annotation', anno_token)\n",
    "            visibility_token = anno['visibility_token']\n",
    "            attribute_tokens = anno['attribute_tokens']\n",
    "            instance_token = anno['instance_token']\n",
    "            attrs = [nusc.get('attribute', token)['name'] for token in attribute_tokens]\n",
    "            visibility = nusc.get('visibility', visibility_token)['level']\n",
    "            diag = corners_8_to_2(details['corners'], meta['image_width'], meta['image_height']) \n",
    "            area = float((diag[0, 1] - diag[0, 0]) * (diag[1, 1] - diag[1, 0]))\n",
    "            annos.append({\n",
    "                'anno_token': anno_token,\n",
    "                'instance_token': instance_token,\n",
    "                'category_name': anno['category_name'],\n",
    "                'box_t': anno['translation'],\n",
    "                'box_r': anno['rotation'],\n",
    "                'box_size': anno['size'],\n",
    "                'visibility': visibility,\n",
    "                'attribute': attrs,\n",
    "                '2d_crop': {\n",
    "                    'diag': diag.tolist(),\n",
    "                    'area': area,\n",
    "                },\n",
    "            })\n",
    "\n",
    "            # dump instance crops\n",
    "            MIN_AREA = 10000\n",
    "            MIN_VIS = 100\n",
    "            vis_val = int(visibility.split('-')[-1])\n",
    "            crop = inst_crops.get(instance_token, None)\n",
    "            if crop is None or area > crop[2]:\n",
    "                if area > MIN_AREA and vis_val >= MIN_VIS:\n",
    "                    inst_crops[instance_token] = [rgb_path, diag, area]\n",
    "\n",
    "        meta['annos'] = annos\n",
    "\n",
    "        with open(anno_path, 'w') as f:\n",
    "            json.dump(meta, f, indent=2)\n",
    "        \n",
    "    # dump instance crops\n",
    "    crop_sc_dir = os.path.join(CROPS_ROOT, sc['token'])\n",
    "    os.makedirs(crop_sc_dir, exist_ok=True)\n",
    "    for inst_token, crop in inst_crops.items():\n",
    "        img_path, diag, area = crop\n",
    "        img_save_path = os.path.join(crop_sc_dir, f'{inst_token}.{POSTFIX}')\n",
    "        # read the image\n",
    "        # crop the image\n",
    "        # save the image\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        img = img.crop((diag[0, 0], diag[1, 0], diag[0, 1], diag[1, 1]))\n",
    "        img.save(img_save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
