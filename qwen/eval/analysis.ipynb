{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abccaefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e22784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def load_ans(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "    return data\n",
    "def json_unwrap(s):\n",
    "    if s.startswith(\"```json\"):\n",
    "        s = s[7:]\n",
    "    if s.endswith(\"```\"):\n",
    "        s = s[:-3]\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"fail to parse json: {s}\")\n",
    "        raise\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d421777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerify(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, str):\n",
    "            try:\n",
    "                d[k] = float(v)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return d\n",
    "\n",
    "def complete_check(gt, pred):\n",
    "    for k in gt:\n",
    "        if k not in pred:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def norm_error(gt, pred):\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    pred = numerify(pred)\n",
    "    dist = sum(\n",
    "        (gt[k] - pred[k]) ** 2 for k in gt\n",
    "    )\n",
    "    gt_norm = sum(\n",
    "        (gt[k] ** 2) for k in gt\n",
    "    )\n",
    "    return min( dist / gt_norm, 1.0 )\n",
    "\n",
    "def thres_error(gt, pred, thres=.5):\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    pred = numerify(pred)\n",
    "    inbound = [\n",
    "        abs((gt[k] - pred[k]) / (gt[k] + 1e-5)) < thres for k in gt\n",
    "    ]\n",
    "\n",
    "    # print(f\"gt: {gt}, pred: {pred}, error: {0 if all(inbound) else 1}\")\n",
    "\n",
    "    return 0 if all(inbound) else 1\n",
    "\n",
    "def identity_error(gt, pred):\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    same = [\n",
    "        gt[k] == pred[k] for k in gt\n",
    "    ]\n",
    "    return 0 if all(same) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456177df",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_meta = \"../../QA/pairs/QA_pairs.test.json\"\n",
    "ans_all = \"./answers_base.json\"\n",
    "\n",
    "popular_error = thres_error\n",
    "\n",
    "QA_meta = load_meta(QA_meta)\n",
    "ans_all = load_ans(ans_all)\n",
    "judger = {\n",
    "    \"single_obj_abs_dist\": popular_error,\n",
    "    \"double_obj_abs_dist\": popular_error,\n",
    "    \"single_obj_minmax_dist\": popular_error,\n",
    "    \"double_obj_minmax_dist\": popular_error,\n",
    "    \"multiple_obj_relative_dist\": identity_error,\n",
    "    \"local_coords\": popular_error,\n",
    "}\n",
    "\n",
    "score = {}\n",
    "dists = []\n",
    "\n",
    "for meta, gt in zip(QA_meta, ans_all):\n",
    "    task_type = meta[\"QA_type\"]\n",
    "    if task_type not in score:\n",
    "        score[task_type] = {\n",
    "            \"num_qa\": 0,\n",
    "            \"errors\": 0,\n",
    "        }\n",
    "\n",
    "    if task_type in judger:\n",
    "        try:\n",
    "            gt_ans = json_unwrap(gt[\"gt_ans\"])\n",
    "            pred_ans = json_unwrap(gt[\"ans\"])\n",
    "        except json.JSONDecodeError:\n",
    "            score[task_type][\"errors\"] += 1.\n",
    "            score[task_type][\"num_qa\"] += 1\n",
    "            continue\n",
    "        if \"dist\" in pred_ans:\n",
    "            dists.append(pred_ans[\"dist\"])\n",
    "        try:\n",
    "            error = judger[task_type](gt_ans, pred_ans)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in task {task_type}: {e}\")\n",
    "            print(f\"gt_ans: {gt_ans}\")\n",
    "            print(f\"pred_ans: {pred_ans}\")\n",
    "        score[task_type][\"errors\"] += error\n",
    "        score[task_type][\"num_qa\"] += 1\n",
    "    else:\n",
    "        print(f\"Unknown task type: {task_type}\")\n",
    "\n",
    "print(json.dumps(score, indent=4))\n",
    "\n",
    "overall = 0.\n",
    "for k, v in score.items():\n",
    "    if v[\"num_qa\"] > 0:\n",
    "        overall += v[\"errors\"] / v[\"num_qa\"]\n",
    "\n",
    "print(f\"Overall score: {1 - overall / len(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(dists, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "# plt.title('Histogram of Distances')\n",
    "dists = np.array(dists, dtype=np.float32)\n",
    "print(f\"stat of dists:\"\n",
    "      f\"\\n total: {len(dists)}, \"\n",
    "      f\"\\n unique: {len(np.unique(dists))}, \"\n",
    "      f\"\\n mean: {np.mean(dists)}, \"\n",
    "      f\"\\n std: {np.std(dists)}, \"\n",
    "      f\"\\n min: {np.min(dists)}, \"\n",
    "      f\"\\n max: {np.max(dists)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
